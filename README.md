# Emotion-Recognition-through-speech

In the emotion recognition from speech system, different feature extraction techniques
are taken into consideration and made SVM classification and MLP classifiers for a
better accuracy. Machine learning model is created from this classifier. It predicts the
human emotions by its previous trained and test sets. The data used for trained the
model is taken form The Ryerson Audio-Visual Database of Emotional Speech and
Song (RAVDESS) which contains audio files of different emotions. Currently, it can
detect 7 emotions : Anger, Calm, Happy, Disgust, Surprise, Sad and Fear. If the model
can have an improvement with additional research, more emotions can be generated.
The project is in a ready-go state to be used by a user to detect whether his tone of
speech in any of these seven emotions.
